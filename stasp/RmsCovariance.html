<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>stasp.RmsCovariance API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>stasp.RmsCovariance</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rms_vs_energy(lcs,ps_v,m=None,freq_low=None,freq_high=None,units=&#39;rms&#39;):
    &#34;&#34;&#34;
    Compute the fractional variance amplitude (rms) for multiple light curves in a given frequency band.
    
    **Parameters**:

    `lcs`: class: list of &#39;Lightcurve&#39;-objects
        The light curves to be used.
    
    `ps_v`: class: list of &#39;PowerSpectrum&#39;-objects
        The corresponding (important!) power spectras to be used.
    
    `m`: int
        Number of bins per segment.
        
    `freq_low/freq_high`: floats
        Lower and upper frequency limits.
        
    `units`: {&#39;abs&#39;,&#39;frac&#39;}, optional, default: &#39;abs&#39;
        What unit to return the rms in.        

           
    **Returns**:

    `energy_mid_v`: np.ndarray 
        The average energy from each light curve&#39;s energy band. 
    
    `energy_err_v`: np.ndarray 
        Half the size of each light curve&#39;s energy band. 
        
    `rms_v`: np.ndarray 
        Absolute/fractional rms.
        
    `rms_err_v`: np.ndarray 
        The error in (absolute/fractional) rms.
    &#34;&#34;&#34;
    
    print(&#39;---------------------------------------------------------------------------------------------------&#39;)
    print(&#39;                           Computing the rms...&#39;)
    print(&#39;---------------------------------------------------------------------------------------------------\n&#39;)
    start = timeit.default_timer()
    
    rms_v, rms_err_v = [], []
    
    for lc,ps in zip(lcs,ps_v):     
        # Find rms                
        rms, rms_err = rms_freqband(ps,lc,m,freq_low,freq_high,units=units)
        
        rms_v.append(rms)
        rms_err_v.append(rms_err)
        
    time_taken = timeit.default_timer()-start
    print(&#39;---------------------------------------------------------------------------------------------------&#39;)
    print(&#39;                           Rms found (in {:.2f} sec).&#39;.format(time_taken))
    print(&#39;---------------------------------------------------------------------------------------------------&#39;)
     
    return np.array(rms_v),np.array(rms_err_v)

def rms_freqband(ps,lc=None,m=None,freq_low=None,freq_high=None,units=&#39;abs&#39;):
    &#34;&#34;&#34;
    Compute the rms in a given frequency band for a given energy (as given by 
    the lightcurve and corresponding power spectrum).
    
    **Parameters**:
    
    `ps`: class: &#39;PowerSpectrum&#39;-object
        The corresponding (important!) power spectra to be used.
        
    `lc`: class &#39;Lightcurve&#39;-object
        The light curve, whose rms is to be found.
    
    `m`: int
        Number of bins per segment.
        
    `freq_low/freq_high`: floats
        Lower and upper frequency limits.
        
    `units`: {&#39;abs&#39;,&#39;frac&#39;}, optional, default: &#39;abs&#39;
        What unit to return the rms in.
        
    **Returns**:
    
    `sigma`: np.float
        Absolute/fractional rms.
    
    `sigma_err`: np.float
        The error in (absolute/fractional) rms. See Eq. (14) of Uttley (2014): &#34;X-ray reverberation around accreting black holes&#34;
    &#34;&#34;&#34;
    
    # Compute rms via light curve first if no freq-boundaries 
    add_to_string = &#39;\n&#39;
    if freq_low == None and freq_high == None:
        if lc != None:
            rms_lc = Fvar_from_lc(lc,m,percent_limit=80) # --&gt; yield the same value
            add_to_string = &#39;, rms_lc = {:.3f}\n&#39;.format(rms_lc)
        
    # Compute rms via power spectrum
    
    # Frequency range
    freq_low = ps.xf[0] if freq_low == None else freq_low
    freq_high = ps.xf[-1] if freq_high == None else freq_high
    dnu = freq_high-freq_low
    
    # Noise Power is constant in freq!
    P_noise = ps.averagePnoise
    
    # Error variance
    if units == &#39;abs&#39;:
        sigma_noise2 = P_noise*dnu*lc.R**2
    elif units == &#39;rms&#39;:
        sigma_noise2 = P_noise*dnu #now it is rather rms, not sigma...
    else:
        print(&#34;You need to pick &#39;abs&#39; or &#39;rms&#39; as unit.&#34;)
    
    # Find rms within the given interval
    xf, [fft_rate,fft_rate_err] = remove_freq(ps.xf,[ps.fft_rate,ps.fft_rate_err],limit=freq_low,geq=True,disregard=True)
    xf, [fft_rate,fft_rate_err] = remove_freq(xf,[fft_rate,fft_rate_err],limit=freq_high,leq=True,disregard=True)
    
    try: 
        rms = np.sqrt(dnu * np.mean(fft_rate)) #\approx same as Fvar_from_ps(xf,fft_rate)
        rms_err = ps.df*np.sqrt(np.sum(fft_rate_err**2))/(2*rms) #error propagation
        
        &#34;&#34;&#34;
        # Version 1: Monte Carlo Estimation 
        # Given one power spectrum (for a given energy) we can use fft_rate (the averages) 
        # and fft_rate_err (the standard errors) to sample new power spectra by sampling new values for the 
        # power spectrum at each frequency point i according to the normal distribution N(fft_rate[i],fft_rate_err[i]).
        num_new_ps = 1000
        # Each frequency bin will yield a num_new_ps-long array that will be appended
        ps_new_v = []
        for i in range(0,len(xf)):
            ps_new_v.append(np.random.normal(fft_rate[i], fft_rate_err[i], num_new_ps))
        # Transpose to make each array become a power spectrum on its own
        ps_new_v = np.transpose(np.array(ps_new_v))
        rms_v = [Fvar_from_ps(xf,f) for f in ps_new_v]
        print(&#39;rms_err_ver1 = &#39;,np.std(rms_v))
        rms_err = np.std(rms_v)

        # Version 2: 
        sigma_err_ver1 = np.sqrt((np.sqrt(1/(2*lc.N))*np.mean(lc.err**2)/(lc.R**2*rms))**2+\
                            (np.sqrt(np.mean(lc.err**2)/lc.N)*1/lc.R)**2) # Eq. B2 Vaughan2003 &#34;On characterizing...&#34; 

        print(&#39;rms_err_ver2 = &#39;,sigma_err_ver1)
        
        # Version 3:
        # In case of unity coherence, the following formula should also work:
        sigma = rms
        sigma_err_ver2 = np.sqrt((2*sigma**2*sigma_noise2+sigma_noise2**2)/(len(lc.t)*sigma**2))
        print(&#39;rms_err_ver3 = &#39;,sigma_err_ver2)
        &#34;&#34;&#34;
 
        if units == &#39;abs&#39;: 
            rms = lc.R*rms
            rms_err = lc.R*rms_err
            &#34;&#34;&#34;
            sigma_err_ver1 = np.sqrt((np.sqrt(1/(2*lc.N))*np.mean(lc.err**2)/(lc.R**2*rms))**2+\
                                     (np.sqrt(np.mean(lc.err**2)/lc.N)*1/lc.R)**2)    
            sigma_err_ver2 = np.sqrt((2*sigma**2*sigma_noise2+sigma_noise2**2)/(len(lc.t)*sigma**2))
            
            rms = sigma
            rms_err = sigma_err
            &#34;&#34;&#34;
            print(&#39;Eband = {:.2f}-{:.2f} keV, Freq range = {:.3f}-{:.3f} Hz, rms_ps = {:.3f} pm {:.3f} ({:.1f}% error), R = {:.3f}&#39;.format(lc.Emin,lc.Emax,freq_low,freq_high,rms,rms_err,rms_err/rms*100,lc.R)+add_to_string)
        else:
            print(&#39;Eband = {:.2f}-{:.2f} keV, Freq range = {:.3f}-{:.3f} Hz, rms_ps = {:.3f} pm {:.3f} ({:.1f}% error)&#39;.format(lc.Emin,lc.Emax,freq_low,freq_high,rms,rms_err,rms_err/rms*100)+add_to_string)
    
    except FloatingPointError:
        rms, rms_err = float(&#39;NaN&#39;), float(&#39;NaN&#39;)
    
    return rms, rms_err


def multiply_w_spectra(lc_v,rms_v,rms_err_v,channel_to_kev,spectral_data):
    &#34;&#34;&#34;
    Multiply rms (or covariance) with spectra to obtain rms/covariance spectra.
    Might only work well for RXTE (where channels are given by their energy max): https://heasarc.gsfc.nasa.gov/docs/xte/e-c_table.html 
    
    **Parameters**:

    `lc_v`: class: list of &#39;Lightcurve&#39;-objects    
        The light curves to be used.
            
    `rms_v`: np.ndarray    
        Absolute/fractional rms.
        
    `rms_err_v`: np.ndarray    
        The error in (absolute/fractional) rms.
        
    `channel_to_kev`: np.ndarray    
        Conversion from channel (index) to energy (keV).
    
    `spectral_data`: dict or None, optional, default: None    
        Spectral data of the observation. If dict, rms is scaled with the spectral_data to yield the rms spectra.
        
    **Returns**:

    `rms_v`: np.ndarray    
        Absolute/fractional rms mulitplied with the spectra.
        
    `rms_err_v`: np.ndarray    
        The error in (absolute/fractional) rms mulitplied with the spectra.
    &#34;&#34;&#34;
    
    print(&#39;Multiplying with spectra. Note: only works for XTE-data atm.&#39;)
    
    for i in range(0,len(rms_v)):
        lc = lc_v[i]

        # Covert channel min/max to energy min/max
        minchan = lc.MINCHAN
        if minchan != 0:
            minchan -= 1 # For RXTE: since each channel only corresponds to its energy max, we need to sub to get its min (the former channel&#39;s max)
        minene = channel_to_kev[minchan]
        if minchan == 0:
            minene = 0
        maxchan = lc.MAXCHAN
        maxene = channel_to_kev[maxchan]

        scale_rms = np.mean(spectral_data[&#39;COUNTS/SEC&#39;][minchan:maxchan])/lc.deltaE
        scale_err = np.mean(spectral_data[&#39;STATERR/SEC&#39;][minchan:maxchan])/lc.deltaE
        #print(&#39;dkeV, counts, scale_rms, scale_err = &#39;,lc.deltaE,&#39;, &#39;,np.mean(data[&#39;COUNTS/SEC&#39;][minchan:maxchan]),&#39;, &#39;,scale_rms,&#39;, &#39;,scale_err,&#39;\n&#39;)

        rms_v[i] *= scale_rms
        rms_err_v[i] *= scale_err
        
    return rms_v, rms_err_v

def covariance(lc_interest_v,lc_ref,m,alt=1,freq_low=None,freq_high=None,noise=&#39;Poisson&#39;,percent_limit=90,units=&#39;abs&#39;,to_plot=False):
    &#34;&#34;&#34;
    Compute the covariance, which is more robust than the rms. 
    
    **Parameters**:

    `lc_interest_v`: list of &#39;Lightcurve&#39;-objects    
        The light curves of interest to be used in the covariance computation. 
         
    `lc_ref`: &#39;Lightcurve&#39;-object       
        Reference light curve.
         
    `m`: int    
        Number of time bins per segment. 
        
    `alt`: int {1, 2}, optional, default: 1    
        What method to compute the covariance with.
        If full freq range: 1 = for whole light curve directly, 2 = segment-wise. 
        If smaller freq range: 1 = using FFT and inverseFFT, 2 = using coherence.
    
    `freq_low/freq_high`: floats, optional, default: None    
        Lower and upper frequency limits.
        
    `noise`: {&#39;Poisson&#39;,&#39;Gaussian&#39;}, optional, default: &#39;Poisson&#39;.    
        For a light curve with &#39;Poisson&#39;/&#39;Gaussian&#39; errors. 
     
    `percent_limit`: float, optional, default: 90    
        Lower limit for percent of time bins having to be filled, i.e. without gaps, for that segment to be used.
    
    `units`: {&#39;abs&#39;,&#39;frac&#39;}, optional, default: &#39;abs&#39;    
        What unit to return the rms in.
    
    `to_plot`: boolean (default: False)    
        If True, a figure for different ways to compute the covariance is displayed. 
        
    **Returns**:

    `cov_v`: array    
        The normalised coviarances as calculated by Eq(2) and Eq(3) from Wilkinson(2009).
        
    `cov_err_v`: array    
        The statistical errors of the covariance.  
    &#34;&#34;&#34;
    
    cov_v, cov_err_v = [], []

    for i in range(0,len(lc_interest_v)):
        lc_v = [lc_interest_v[i],lc_ref]
    
        print(&#39;---------------------------------------------------------------------------------------------------&#39;)
        print(&#39;                           Covariance computation about to begin...&#39;)
        print(&#39;---------------------------------------------------------------------------------------------------\n&#39;)

        start = timeit.default_timer()

        if np.all(lc_v[0].rate == lc_v[1].rate):
            print(&#39;The light curves are the same! Try again.\n&#39;)
            continue
            
        print(&#39;Light curve 1: {}-{} keV&#39;.format(lc_v[0].Emin,lc_v[0].Emax))
        print(&#39;Light curve 2: {}-{} keV (this is the reference band)\n&#39;.format(lc_v[1].Emin,lc_v[1].Emax))

        # If overlapping energy bands, this needs to be handled
        lc_v = subtract_overlapping_energybands(lc_v)

        # Extract data
        lc_X = lc_v[0]
        t_X, rate_X, err_X, R_X = lc_X.t, lc_X.rate, lc_X.err, lc_X.R
        # and from Reference Band:
        lc_Y = lc_v[1]
        t_Y, rate_Y, err_Y, R_Y = lc_Y.t, lc_Y.rate, lc_Y.err, lc_Y.R

        errX = np.mean(err_X**2)
        errY = np.mean(err_Y**2)

        comparison = t_X == t_Y
        assert comparison.all(), &#39;Time arrays are not identical. The two light curves must come from the same observation...&#39;

        # Useful parameters (take from reference band, but is the same as the corresponding X-band values)
        dt = t_Y[1]-t_Y[0]
        N = len(t_Y)

        # Full frequency range
        if freq_low == None and freq_high == None: 

            if alt == 1:
                ## ------------------------------------ Cov for whole light curve ---------------------------------------------
                print(&#39;---------------------------------------------------------------------------------------------------&#39;)
                print(&#39;                           Computing covariance for whole light curve directly...&#39;)
                print(&#39;---------------------------------------------------------------------------------------------------\n&#39;)

                # Prep Work to normalize covariance and to compute covariance error
                errX = np.mean(err_X**2)
                errY = np.mean(err_Y**2)

                var_ex_X_lc = 1/(len(rate_X)-1)*np.sum((rate_X-np.mean(rate_X))**2)-errX
                var_ex_Y_lc = 1/(len(rate_Y)-1)*np.sum((rate_Y-np.mean(rate_Y))**2)-errY
                print(&#39;var_ex_X_lc = {}, var_ex_Y_lc (ref) = {}&#39;.format(var_ex_X_lc,var_ex_Y_lc))
                if var_ex_X_lc &gt; var_ex_Y_lc:
                    print(&#34;Note that the reference band should be the band with highest absolute variability; this is not the case here.&#34;)
                    print(&#39;var_ex_X_lc = {}, var_ex_Y_lc (ref) = {}&#39;.format(var_ex_X_lc,var_ex_Y_lc))
                Fvar_lc = np.sqrt(var_ex_Y_lc)/np.mean(rate_Y) 

                # Compute Covariance
                cov = 1/(len(rate_Y)-1)*np.sum((rate_X-np.mean(rate_X))*(rate_Y-np.mean(rate_Y)))

                # Normalize
                cov = cov/np.sqrt(var_ex_Y_lc)
                # Error
                cov_err = np.sqrt((var_ex_X_lc*errY+var_ex_Y_lc*errX+errX*errY)/(len(t_X)*var_ex_Y_lc))

                if units != &#39;abs&#39;: 
                    cov /= R_X 
                    cov_err /= R_X

                print(&#39;Cov = &#39;,cov,&#39; pm &#39;,cov_err,&#39;\n&#39;)

            elif alt == 2:
                ## ------------------------------------- Cov for segments ---------------------------------------------------------
                print(&#39;---------------------------------------------------------------------------------------------------&#39;)
                print(&#39;                           Computing covariance segment-wise...&#39;)
                print(&#39;---------------------------------------------------------------------------------------------------\n&#39;)

                # Prep Work to normalize covariance and to compute covariance error
                ps_X = PowerSpectrum(lc_v[0],m=m,percent_limit=percent_limit,noise=noise,timer_on=False,save_all=True)
                ps_Y = PowerSpectrum(lc_v[1],m=m,percent_limit=percent_limit,noise=noise,timer_on=False,save_all=True)

                fft_rate_meanX = ps_X.fft_rate
                fft_rate_meanY = ps_Y.fft_rate

                var_ex_X = [1/(m-1)*np.sum((rate_seg-R_seg)**2)-np.mean(err_seg**2) for rate_seg, R_seg, err_seg in zip(ps_X.rate_seg, ps_X.R_seg, ps_X.err_seg)]
                var_ex_Y = [1/(m-1)*np.sum((rate_seg-R_seg)**2)-np.mean(err_seg**2) for rate_seg, R_seg, err_seg in zip(ps_Y.rate_seg, ps_Y.R_seg, ps_Y.err_seg)]

                var_err_X = [np.mean(e**2) for e in ps_X.err_seg]
                var_err_Y = [np.mean(e**2) for e in ps_Y.err_seg]

                P_X_mean = np.mean(ps_X.fft_rate)
                P_Y_mean = np.mean(ps_Y.fft_rate)

                # Should we take the average over all segments to get the final variance error? 
                var_err_X_mean = np.mean(var_err_X,axis=0)
                var_err_Y_mean = np.mean(var_err_Y,axis=0)

                # Excess Variance 
                var_ex_X_lc = np.mean(var_ex_X)
                var_ex_Y_lc = np.mean(var_ex_Y)
                if var_ex_X_lc &gt; var_ex_Y_lc:
                    print(&#34;Note that the reference band should be the band with highest absolute variability; this is not the case here.&#34;)
                    print(&#39;var_ex_X_lc = {}, var_ex_Y_lc (ref) = {}&#39;.format(var_ex_X_lc,var_ex_Y_lc))

                # Quantities neeeded:
                cov = [1/(m-1)*np.sum((rate_seg_X-R_X_seg)*(rate_seg_Y-R_Y_seg)) for rate_seg_X, rate_seg_Y, R_X_seg, R_Y_seg in zip(ps_X.rate_seg, ps_Y.rate_seg, ps_X.R_seg, ps_Y.R_seg)]
                if units != &#39;abs&#39;: 
                    cov = [c/R for c,R in zip(cov,ps_X.R_seg)]

                # 1) Small difference between taking average over all covariances and using full excess variance to normalize
                cov_mean = np.mean(cov,axis=0)
                cov_norm_alt1 = cov_mean/np.sqrt(var_ex_Y_lc)
                print(&#39;cov_norm = &#39;,cov_norm_alt1)
                # 2) vs using excess variance from each segment to normalize and then taking the average 
                cov_seg_norm = np.array(cov)/np.sqrt(var_ex_Y)
                cov_norm_alt2 = np.mean(cov_seg_norm,axis=0)
                print(&#39;cov_norm = &#39;,cov_norm_alt2)

                cov = cov_norm_alt2
                cov_err = np.sqrt((var_ex_X_lc*var_err_Y_mean+var_ex_Y_lc*var_ex_X_lc+var_err_X_mean*var_err_Y_mean)/(N*var_ex_Y_lc))
                if units != &#39;abs&#39;: 
                    cov_err /= R_X
                print(&#39;Cov = &#39;,cov,&#39; pm &#39;,cov_err,&#39;\n&#39;)

        # If not full freq. range
        else:
            if alt == 1:
                ## ------------------------------------ Cov using FFT and inverseFFT ---------------------------------------------       
                print(&#39;---------------------------------------------------------------------------------------------------&#39;)
                print(&#39;                           Computing covariance using FFT and inverseFFT...&#39;)
                print(&#39;---------------------------------------------------------------------------------------------------\n&#39;)

                print(&#39;Perform FFT and IFFT to extract light curves with variability only in the given freq band.\n&#39;)

                xf = np.array(fftfreq(N, dt))[1:N//2]
                # Pick out frequency range 
                if freq_low == None:
                    freq_low = xf[0]
                if freq_high == None:
                    freq_high = xf[-1]

                rate_X = pick_out_freq_from_lc(lc_v[0], freq_low, freq_high)
                rate_Y = pick_out_freq_from_lc(lc_v[1], freq_low, freq_high)

                print(&#39;Find excess variance through the rms (i.e. from a normalized power spectra) in the given freq range.\n&#39;)
                # rms needs to be taken from normalized power spectra in the relevant freq range
                ps_X, ps_Y = PowerSpectrum(lc_v[0],m=N,timer_on=False,noise=noise,save_all=True,percent_limit=0), PowerSpectrum(lc_v[1],m=N,timer_on=False,noise=noise,save_all=True,percent_limit=0)
                fft_rate_meanX, fft_rate_meanY = ps_X.fft_rate, ps_Y.fft_rate

                xf, fft_rates = remove_freq(xf,[fft_rate_meanX,fft_rate_meanY],freq_low,geq=True,disregard=False)
                xf, fft_rates = remove_freq(xf,[fft_rates[0],fft_rates[1]],freq_high,leq=True,disregard=False)

                FvarX, FvarY = Fvar_from_ps(xf, fft_rates[0]), Fvar_from_ps(xf, fft_rates[1])
                #print(&#39;FvarY = &#39;,FvarY)
                var_ex_X_lc, var_ex_Y_lc = (FvarX * R_X)**2, (FvarY * R_Y)**2
                if var_ex_X_lc &gt; var_ex_Y_lc:
                    print(&#34;Note that the reference band should be the band with highest absolute variability; this is not the case here.&#34;)
                    print(&#39;var_ex_X_lc = {}, var_ex_Y_lc (ref) = {}&#39;.format(var_ex_X_lc,var_ex_Y_lc))

                # Compute cov
                cov = 1/(len(rate_Y)-1)*np.sum((rate_X-np.mean(rate_X))*(rate_Y-np.mean(rate_Y)))
                # Normalize                                     
                cov = cov/np.sqrt(var_ex_Y_lc)

                # Error
                P_noise_X_full = np.mean(err_X**2)/(R_X**2*1/(2*dt))
                P_noise_Y_full = np.mean(err_Y**2)/(R_Y**2*1/(2*dt))
                errX = P_noise_X_full*R_X**2*(freq_high-freq_low)
                errY = P_noise_Y_full*R_Y**2*(freq_high-freq_low)
                cov_err = np.sqrt((var_ex_X_lc*errY+var_ex_Y_lc*errX+errX*errY)/(len(t_X)*var_ex_Y_lc))

                if units != &#39;abs&#39;: 
                    cov /= R_X 
                    cov_err /= R_X
                print(&#39;Cov = &#39;,cov,&#39; pm &#39;,cov_err,&#39;\n&#39;)

            elif alt == 2:
                ## ----------------------------------------------- Cov using coherence ------------------------------------------------------------
                print(&#39;---------------------------------------------------------------------------------------------------&#39;)
                print(&#39;                          Covariance using coherence...&#39;)
                print(&#39;---------------------------------------------------------------------------------------------------\n&#39;)

                upper_freq_lim = freq_high
                assert upper_freq_lim != None, &#34;You need to set an upper freq. limit; will be the same for all lc.&#34;

                # Compute intrinsic coherence 
                xf_coh, gamma2, delta_gamma2_int = coherence_intrinsic(lc_v,m_init=2**16)
                xf_coh, gamma2 = remove_freq(xf_coh,gamma2,limit=upper_freq_lim,leq=True)
                dnu = upper_freq_lim-xf_coh[0]

                # Should use the fft_rate_meanX/fft_rate_meanY from the coherence computation (that uses different m), 
                # but this is not implemented...
                # ---- This part will do until fixed.  Small difference... -----------
                ps_X = PowerSpectrum(lc_v[0],m=m,percent_limit=percent_limit,noise=noise,timer_on=False,save_all=True)
                ps_Y = PowerSpectrum(lc_v[1],m=m,percent_limit=percent_limit,noise=noise,timer_on=False,save_all=True)
                xf = ps_X.xf

                fft_rate_meanX = ps_X.fft_rate
                fft_rate_meanY = ps_Y.fft_rate

                # ----------------------------------------------------------------------------------------------------

                _, fft_rate_meanX_test = remove_freq(xf,fft_rate_meanX,limit=upper_freq_lim,leq=True)
                P_X_mean = np.mean(fft_rate_meanX_test)

                _, fft_rate_meanY_test = remove_freq(xf,fft_rate_meanY,limit=upper_freq_lim,leq=True)
                P_Y_mean = np.mean(fft_rate_meanY_test)

                # Compute covariance
                cov = R_X*np.sqrt(np.mean(gamma2)*P_X_mean*dnu)
                print(&#39;Cov = &#39;,cov)

                # Error
                P_noise_X_full = np.mean(err_X**2)/(R_X**2*1/(2*dt))
                P_noise_Y_full = np.mean(err_Y**2)/(R_Y**2*1/(2*dt))

                errX = R_X*P_noise_X_full*dnu
                errY = R_Y*P_noise_Y_full*dnu
                var_ex_X_lc = R_X*P_X_mean*dnu
                var_ex_Y_lc = R_Y*P_Y_mean*dnu
                if var_ex_X_lc &gt; var_ex_Y_lc:
                    print(&#34;Note that the reference band should be the band with highest absolute variability; this is not the case here.&#34;)
                    print(&#39;var_ex_X_lc = {}, var_ex_Y_lc (ref) = {}&#39;.format(var_ex_X_lc,var_ex_Y_lc))

                cov_err = np.sqrt((cov**2*errY+var_ex_Y_lc*errX+errX*errY)/(len(t_X)*var_ex_Y_lc))

                if units != &#39;abs&#39;: 
                    cov /= R_X 
                    cov_err /= R_X

                print(&#39;Cov = &#39;,cov,&#39; pm &#39;,cov_err,&#39;\n&#39;)

        time_taken = timeit.default_timer()-start
        print(&#39;---------------------------------------------------------------------------------------------------&#39;)
        print(&#39;                           Covariance found (in {:.2f} sec).&#39;.format(time_taken))
        print(&#39;---------------------------------------------------------------------------------------------------&#39;) 
    
        cov_v.append(cov)
        cov_err_v.append(cov_err)
    
    return cov_v, cov_err_v</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="stasp.RmsCovariance.covariance"><code class="name flex">
<span>def <span class="ident">covariance</span></span>(<span>lc_interest_v, lc_ref, m, alt=1, freq_low=None, freq_high=None, noise='Poisson', percent_limit=90, units='abs', to_plot=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the covariance, which is more robust than the rms. </p>
<p><strong>Parameters</strong>:</p>
<p><code>lc_interest_v</code>: list of 'Lightcurve'-objects
<br>
The light curves of interest to be used in the covariance computation. </p>
<p><code>lc_ref</code>: 'Lightcurve'-object
<br>
Reference light curve.</p>
<p><code>m</code>: int
<br>
Number of time bins per segment. </p>
<p><code>alt</code>: int {1, 2}, optional, default: 1
<br>
What method to compute the covariance with.
If full freq range: 1 = for whole light curve directly, 2 = segment-wise.
If smaller freq range: 1 = using FFT and inverseFFT, 2 = using coherence.</p>
<p><code>freq_low/freq_high</code>: floats, optional, default: None
<br>
Lower and upper frequency limits.</p>
<p><code>noise</code>: {'Poisson','Gaussian'}, optional, default: 'Poisson'.
<br>
For a light curve with 'Poisson'/'Gaussian' errors. </p>
<p><code>percent_limit</code>: float, optional, default: 90
<br>
Lower limit for percent of time bins having to be filled, i.e. without gaps, for that segment to be used.</p>
<p><code>units</code>: {'abs','frac'}, optional, default: 'abs'
<br>
What unit to return the rms in.</p>
<p><code>to_plot</code>: boolean (default: False)
<br>
If True, a figure for different ways to compute the covariance is displayed. </p>
<p><strong>Returns</strong>:</p>
<p><code>cov_v</code>: array
<br>
The normalised coviarances as calculated by Eq(2) and Eq(3) from Wilkinson(2009).</p>
<p><code>cov_err_v</code>: array
<br>
The statistical errors of the covariance.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def covariance(lc_interest_v,lc_ref,m,alt=1,freq_low=None,freq_high=None,noise=&#39;Poisson&#39;,percent_limit=90,units=&#39;abs&#39;,to_plot=False):
    &#34;&#34;&#34;
    Compute the covariance, which is more robust than the rms. 
    
    **Parameters**:

    `lc_interest_v`: list of &#39;Lightcurve&#39;-objects    
        The light curves of interest to be used in the covariance computation. 
         
    `lc_ref`: &#39;Lightcurve&#39;-object       
        Reference light curve.
         
    `m`: int    
        Number of time bins per segment. 
        
    `alt`: int {1, 2}, optional, default: 1    
        What method to compute the covariance with.
        If full freq range: 1 = for whole light curve directly, 2 = segment-wise. 
        If smaller freq range: 1 = using FFT and inverseFFT, 2 = using coherence.
    
    `freq_low/freq_high`: floats, optional, default: None    
        Lower and upper frequency limits.
        
    `noise`: {&#39;Poisson&#39;,&#39;Gaussian&#39;}, optional, default: &#39;Poisson&#39;.    
        For a light curve with &#39;Poisson&#39;/&#39;Gaussian&#39; errors. 
     
    `percent_limit`: float, optional, default: 90    
        Lower limit for percent of time bins having to be filled, i.e. without gaps, for that segment to be used.
    
    `units`: {&#39;abs&#39;,&#39;frac&#39;}, optional, default: &#39;abs&#39;    
        What unit to return the rms in.
    
    `to_plot`: boolean (default: False)    
        If True, a figure for different ways to compute the covariance is displayed. 
        
    **Returns**:

    `cov_v`: array    
        The normalised coviarances as calculated by Eq(2) and Eq(3) from Wilkinson(2009).
        
    `cov_err_v`: array    
        The statistical errors of the covariance.  
    &#34;&#34;&#34;
    
    cov_v, cov_err_v = [], []

    for i in range(0,len(lc_interest_v)):
        lc_v = [lc_interest_v[i],lc_ref]
    
        print(&#39;---------------------------------------------------------------------------------------------------&#39;)
        print(&#39;                           Covariance computation about to begin...&#39;)
        print(&#39;---------------------------------------------------------------------------------------------------\n&#39;)

        start = timeit.default_timer()

        if np.all(lc_v[0].rate == lc_v[1].rate):
            print(&#39;The light curves are the same! Try again.\n&#39;)
            continue
            
        print(&#39;Light curve 1: {}-{} keV&#39;.format(lc_v[0].Emin,lc_v[0].Emax))
        print(&#39;Light curve 2: {}-{} keV (this is the reference band)\n&#39;.format(lc_v[1].Emin,lc_v[1].Emax))

        # If overlapping energy bands, this needs to be handled
        lc_v = subtract_overlapping_energybands(lc_v)

        # Extract data
        lc_X = lc_v[0]
        t_X, rate_X, err_X, R_X = lc_X.t, lc_X.rate, lc_X.err, lc_X.R
        # and from Reference Band:
        lc_Y = lc_v[1]
        t_Y, rate_Y, err_Y, R_Y = lc_Y.t, lc_Y.rate, lc_Y.err, lc_Y.R

        errX = np.mean(err_X**2)
        errY = np.mean(err_Y**2)

        comparison = t_X == t_Y
        assert comparison.all(), &#39;Time arrays are not identical. The two light curves must come from the same observation...&#39;

        # Useful parameters (take from reference band, but is the same as the corresponding X-band values)
        dt = t_Y[1]-t_Y[0]
        N = len(t_Y)

        # Full frequency range
        if freq_low == None and freq_high == None: 

            if alt == 1:
                ## ------------------------------------ Cov for whole light curve ---------------------------------------------
                print(&#39;---------------------------------------------------------------------------------------------------&#39;)
                print(&#39;                           Computing covariance for whole light curve directly...&#39;)
                print(&#39;---------------------------------------------------------------------------------------------------\n&#39;)

                # Prep Work to normalize covariance and to compute covariance error
                errX = np.mean(err_X**2)
                errY = np.mean(err_Y**2)

                var_ex_X_lc = 1/(len(rate_X)-1)*np.sum((rate_X-np.mean(rate_X))**2)-errX
                var_ex_Y_lc = 1/(len(rate_Y)-1)*np.sum((rate_Y-np.mean(rate_Y))**2)-errY
                print(&#39;var_ex_X_lc = {}, var_ex_Y_lc (ref) = {}&#39;.format(var_ex_X_lc,var_ex_Y_lc))
                if var_ex_X_lc &gt; var_ex_Y_lc:
                    print(&#34;Note that the reference band should be the band with highest absolute variability; this is not the case here.&#34;)
                    print(&#39;var_ex_X_lc = {}, var_ex_Y_lc (ref) = {}&#39;.format(var_ex_X_lc,var_ex_Y_lc))
                Fvar_lc = np.sqrt(var_ex_Y_lc)/np.mean(rate_Y) 

                # Compute Covariance
                cov = 1/(len(rate_Y)-1)*np.sum((rate_X-np.mean(rate_X))*(rate_Y-np.mean(rate_Y)))

                # Normalize
                cov = cov/np.sqrt(var_ex_Y_lc)
                # Error
                cov_err = np.sqrt((var_ex_X_lc*errY+var_ex_Y_lc*errX+errX*errY)/(len(t_X)*var_ex_Y_lc))

                if units != &#39;abs&#39;: 
                    cov /= R_X 
                    cov_err /= R_X

                print(&#39;Cov = &#39;,cov,&#39; pm &#39;,cov_err,&#39;\n&#39;)

            elif alt == 2:
                ## ------------------------------------- Cov for segments ---------------------------------------------------------
                print(&#39;---------------------------------------------------------------------------------------------------&#39;)
                print(&#39;                           Computing covariance segment-wise...&#39;)
                print(&#39;---------------------------------------------------------------------------------------------------\n&#39;)

                # Prep Work to normalize covariance and to compute covariance error
                ps_X = PowerSpectrum(lc_v[0],m=m,percent_limit=percent_limit,noise=noise,timer_on=False,save_all=True)
                ps_Y = PowerSpectrum(lc_v[1],m=m,percent_limit=percent_limit,noise=noise,timer_on=False,save_all=True)

                fft_rate_meanX = ps_X.fft_rate
                fft_rate_meanY = ps_Y.fft_rate

                var_ex_X = [1/(m-1)*np.sum((rate_seg-R_seg)**2)-np.mean(err_seg**2) for rate_seg, R_seg, err_seg in zip(ps_X.rate_seg, ps_X.R_seg, ps_X.err_seg)]
                var_ex_Y = [1/(m-1)*np.sum((rate_seg-R_seg)**2)-np.mean(err_seg**2) for rate_seg, R_seg, err_seg in zip(ps_Y.rate_seg, ps_Y.R_seg, ps_Y.err_seg)]

                var_err_X = [np.mean(e**2) for e in ps_X.err_seg]
                var_err_Y = [np.mean(e**2) for e in ps_Y.err_seg]

                P_X_mean = np.mean(ps_X.fft_rate)
                P_Y_mean = np.mean(ps_Y.fft_rate)

                # Should we take the average over all segments to get the final variance error? 
                var_err_X_mean = np.mean(var_err_X,axis=0)
                var_err_Y_mean = np.mean(var_err_Y,axis=0)

                # Excess Variance 
                var_ex_X_lc = np.mean(var_ex_X)
                var_ex_Y_lc = np.mean(var_ex_Y)
                if var_ex_X_lc &gt; var_ex_Y_lc:
                    print(&#34;Note that the reference band should be the band with highest absolute variability; this is not the case here.&#34;)
                    print(&#39;var_ex_X_lc = {}, var_ex_Y_lc (ref) = {}&#39;.format(var_ex_X_lc,var_ex_Y_lc))

                # Quantities neeeded:
                cov = [1/(m-1)*np.sum((rate_seg_X-R_X_seg)*(rate_seg_Y-R_Y_seg)) for rate_seg_X, rate_seg_Y, R_X_seg, R_Y_seg in zip(ps_X.rate_seg, ps_Y.rate_seg, ps_X.R_seg, ps_Y.R_seg)]
                if units != &#39;abs&#39;: 
                    cov = [c/R for c,R in zip(cov,ps_X.R_seg)]

                # 1) Small difference between taking average over all covariances and using full excess variance to normalize
                cov_mean = np.mean(cov,axis=0)
                cov_norm_alt1 = cov_mean/np.sqrt(var_ex_Y_lc)
                print(&#39;cov_norm = &#39;,cov_norm_alt1)
                # 2) vs using excess variance from each segment to normalize and then taking the average 
                cov_seg_norm = np.array(cov)/np.sqrt(var_ex_Y)
                cov_norm_alt2 = np.mean(cov_seg_norm,axis=0)
                print(&#39;cov_norm = &#39;,cov_norm_alt2)

                cov = cov_norm_alt2
                cov_err = np.sqrt((var_ex_X_lc*var_err_Y_mean+var_ex_Y_lc*var_ex_X_lc+var_err_X_mean*var_err_Y_mean)/(N*var_ex_Y_lc))
                if units != &#39;abs&#39;: 
                    cov_err /= R_X
                print(&#39;Cov = &#39;,cov,&#39; pm &#39;,cov_err,&#39;\n&#39;)

        # If not full freq. range
        else:
            if alt == 1:
                ## ------------------------------------ Cov using FFT and inverseFFT ---------------------------------------------       
                print(&#39;---------------------------------------------------------------------------------------------------&#39;)
                print(&#39;                           Computing covariance using FFT and inverseFFT...&#39;)
                print(&#39;---------------------------------------------------------------------------------------------------\n&#39;)

                print(&#39;Perform FFT and IFFT to extract light curves with variability only in the given freq band.\n&#39;)

                xf = np.array(fftfreq(N, dt))[1:N//2]
                # Pick out frequency range 
                if freq_low == None:
                    freq_low = xf[0]
                if freq_high == None:
                    freq_high = xf[-1]

                rate_X = pick_out_freq_from_lc(lc_v[0], freq_low, freq_high)
                rate_Y = pick_out_freq_from_lc(lc_v[1], freq_low, freq_high)

                print(&#39;Find excess variance through the rms (i.e. from a normalized power spectra) in the given freq range.\n&#39;)
                # rms needs to be taken from normalized power spectra in the relevant freq range
                ps_X, ps_Y = PowerSpectrum(lc_v[0],m=N,timer_on=False,noise=noise,save_all=True,percent_limit=0), PowerSpectrum(lc_v[1],m=N,timer_on=False,noise=noise,save_all=True,percent_limit=0)
                fft_rate_meanX, fft_rate_meanY = ps_X.fft_rate, ps_Y.fft_rate

                xf, fft_rates = remove_freq(xf,[fft_rate_meanX,fft_rate_meanY],freq_low,geq=True,disregard=False)
                xf, fft_rates = remove_freq(xf,[fft_rates[0],fft_rates[1]],freq_high,leq=True,disregard=False)

                FvarX, FvarY = Fvar_from_ps(xf, fft_rates[0]), Fvar_from_ps(xf, fft_rates[1])
                #print(&#39;FvarY = &#39;,FvarY)
                var_ex_X_lc, var_ex_Y_lc = (FvarX * R_X)**2, (FvarY * R_Y)**2
                if var_ex_X_lc &gt; var_ex_Y_lc:
                    print(&#34;Note that the reference band should be the band with highest absolute variability; this is not the case here.&#34;)
                    print(&#39;var_ex_X_lc = {}, var_ex_Y_lc (ref) = {}&#39;.format(var_ex_X_lc,var_ex_Y_lc))

                # Compute cov
                cov = 1/(len(rate_Y)-1)*np.sum((rate_X-np.mean(rate_X))*(rate_Y-np.mean(rate_Y)))
                # Normalize                                     
                cov = cov/np.sqrt(var_ex_Y_lc)

                # Error
                P_noise_X_full = np.mean(err_X**2)/(R_X**2*1/(2*dt))
                P_noise_Y_full = np.mean(err_Y**2)/(R_Y**2*1/(2*dt))
                errX = P_noise_X_full*R_X**2*(freq_high-freq_low)
                errY = P_noise_Y_full*R_Y**2*(freq_high-freq_low)
                cov_err = np.sqrt((var_ex_X_lc*errY+var_ex_Y_lc*errX+errX*errY)/(len(t_X)*var_ex_Y_lc))

                if units != &#39;abs&#39;: 
                    cov /= R_X 
                    cov_err /= R_X
                print(&#39;Cov = &#39;,cov,&#39; pm &#39;,cov_err,&#39;\n&#39;)

            elif alt == 2:
                ## ----------------------------------------------- Cov using coherence ------------------------------------------------------------
                print(&#39;---------------------------------------------------------------------------------------------------&#39;)
                print(&#39;                          Covariance using coherence...&#39;)
                print(&#39;---------------------------------------------------------------------------------------------------\n&#39;)

                upper_freq_lim = freq_high
                assert upper_freq_lim != None, &#34;You need to set an upper freq. limit; will be the same for all lc.&#34;

                # Compute intrinsic coherence 
                xf_coh, gamma2, delta_gamma2_int = coherence_intrinsic(lc_v,m_init=2**16)
                xf_coh, gamma2 = remove_freq(xf_coh,gamma2,limit=upper_freq_lim,leq=True)
                dnu = upper_freq_lim-xf_coh[0]

                # Should use the fft_rate_meanX/fft_rate_meanY from the coherence computation (that uses different m), 
                # but this is not implemented...
                # ---- This part will do until fixed.  Small difference... -----------
                ps_X = PowerSpectrum(lc_v[0],m=m,percent_limit=percent_limit,noise=noise,timer_on=False,save_all=True)
                ps_Y = PowerSpectrum(lc_v[1],m=m,percent_limit=percent_limit,noise=noise,timer_on=False,save_all=True)
                xf = ps_X.xf

                fft_rate_meanX = ps_X.fft_rate
                fft_rate_meanY = ps_Y.fft_rate

                # ----------------------------------------------------------------------------------------------------

                _, fft_rate_meanX_test = remove_freq(xf,fft_rate_meanX,limit=upper_freq_lim,leq=True)
                P_X_mean = np.mean(fft_rate_meanX_test)

                _, fft_rate_meanY_test = remove_freq(xf,fft_rate_meanY,limit=upper_freq_lim,leq=True)
                P_Y_mean = np.mean(fft_rate_meanY_test)

                # Compute covariance
                cov = R_X*np.sqrt(np.mean(gamma2)*P_X_mean*dnu)
                print(&#39;Cov = &#39;,cov)

                # Error
                P_noise_X_full = np.mean(err_X**2)/(R_X**2*1/(2*dt))
                P_noise_Y_full = np.mean(err_Y**2)/(R_Y**2*1/(2*dt))

                errX = R_X*P_noise_X_full*dnu
                errY = R_Y*P_noise_Y_full*dnu
                var_ex_X_lc = R_X*P_X_mean*dnu
                var_ex_Y_lc = R_Y*P_Y_mean*dnu
                if var_ex_X_lc &gt; var_ex_Y_lc:
                    print(&#34;Note that the reference band should be the band with highest absolute variability; this is not the case here.&#34;)
                    print(&#39;var_ex_X_lc = {}, var_ex_Y_lc (ref) = {}&#39;.format(var_ex_X_lc,var_ex_Y_lc))

                cov_err = np.sqrt((cov**2*errY+var_ex_Y_lc*errX+errX*errY)/(len(t_X)*var_ex_Y_lc))

                if units != &#39;abs&#39;: 
                    cov /= R_X 
                    cov_err /= R_X

                print(&#39;Cov = &#39;,cov,&#39; pm &#39;,cov_err,&#39;\n&#39;)

        time_taken = timeit.default_timer()-start
        print(&#39;---------------------------------------------------------------------------------------------------&#39;)
        print(&#39;                           Covariance found (in {:.2f} sec).&#39;.format(time_taken))
        print(&#39;---------------------------------------------------------------------------------------------------&#39;) 
    
        cov_v.append(cov)
        cov_err_v.append(cov_err)
    
    return cov_v, cov_err_v</code></pre>
</details>
</dd>
<dt id="stasp.RmsCovariance.multiply_w_spectra"><code class="name flex">
<span>def <span class="ident">multiply_w_spectra</span></span>(<span>lc_v, rms_v, rms_err_v, channel_to_kev, spectral_data)</span>
</code></dt>
<dd>
<div class="desc"><p>Multiply rms (or covariance) with spectra to obtain rms/covariance spectra.
Might only work well for RXTE (where channels are given by their energy max): <a href="https://heasarc.gsfc.nasa.gov/docs/xte/e-c_table.html">https://heasarc.gsfc.nasa.gov/docs/xte/e-c_table.html</a> </p>
<p><strong>Parameters</strong>:</p>
<p><code>lc_v</code>: class: list of 'Lightcurve'-objects
<br>
The light curves to be used.</p>
<p><code>rms_v</code>: np.ndarray
<br>
Absolute/fractional rms.</p>
<p><code>rms_err_v</code>: np.ndarray
<br>
The error in (absolute/fractional) rms.</p>
<p><code>channel_to_kev</code>: np.ndarray
<br>
Conversion from channel (index) to energy (keV).</p>
<p><code>spectral_data</code>: dict or None, optional, default: None
<br>
Spectral data of the observation. If dict, rms is scaled with the spectral_data to yield the rms spectra.</p>
<p><strong>Returns</strong>:</p>
<p><code>rms_v</code>: np.ndarray
<br>
Absolute/fractional rms mulitplied with the spectra.</p>
<p><code>rms_err_v</code>: np.ndarray
<br>
The error in (absolute/fractional) rms mulitplied with the spectra.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def multiply_w_spectra(lc_v,rms_v,rms_err_v,channel_to_kev,spectral_data):
    &#34;&#34;&#34;
    Multiply rms (or covariance) with spectra to obtain rms/covariance spectra.
    Might only work well for RXTE (where channels are given by their energy max): https://heasarc.gsfc.nasa.gov/docs/xte/e-c_table.html 
    
    **Parameters**:

    `lc_v`: class: list of &#39;Lightcurve&#39;-objects    
        The light curves to be used.
            
    `rms_v`: np.ndarray    
        Absolute/fractional rms.
        
    `rms_err_v`: np.ndarray    
        The error in (absolute/fractional) rms.
        
    `channel_to_kev`: np.ndarray    
        Conversion from channel (index) to energy (keV).
    
    `spectral_data`: dict or None, optional, default: None    
        Spectral data of the observation. If dict, rms is scaled with the spectral_data to yield the rms spectra.
        
    **Returns**:

    `rms_v`: np.ndarray    
        Absolute/fractional rms mulitplied with the spectra.
        
    `rms_err_v`: np.ndarray    
        The error in (absolute/fractional) rms mulitplied with the spectra.
    &#34;&#34;&#34;
    
    print(&#39;Multiplying with spectra. Note: only works for XTE-data atm.&#39;)
    
    for i in range(0,len(rms_v)):
        lc = lc_v[i]

        # Covert channel min/max to energy min/max
        minchan = lc.MINCHAN
        if minchan != 0:
            minchan -= 1 # For RXTE: since each channel only corresponds to its energy max, we need to sub to get its min (the former channel&#39;s max)
        minene = channel_to_kev[minchan]
        if minchan == 0:
            minene = 0
        maxchan = lc.MAXCHAN
        maxene = channel_to_kev[maxchan]

        scale_rms = np.mean(spectral_data[&#39;COUNTS/SEC&#39;][minchan:maxchan])/lc.deltaE
        scale_err = np.mean(spectral_data[&#39;STATERR/SEC&#39;][minchan:maxchan])/lc.deltaE
        #print(&#39;dkeV, counts, scale_rms, scale_err = &#39;,lc.deltaE,&#39;, &#39;,np.mean(data[&#39;COUNTS/SEC&#39;][minchan:maxchan]),&#39;, &#39;,scale_rms,&#39;, &#39;,scale_err,&#39;\n&#39;)

        rms_v[i] *= scale_rms
        rms_err_v[i] *= scale_err
        
    return rms_v, rms_err_v</code></pre>
</details>
</dd>
<dt id="stasp.RmsCovariance.rms_freqband"><code class="name flex">
<span>def <span class="ident">rms_freqband</span></span>(<span>ps, lc=None, m=None, freq_low=None, freq_high=None, units='abs')</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the rms in a given frequency band for a given energy (as given by
the lightcurve and corresponding power spectrum).</p>
<p><strong>Parameters</strong>:</p>
<p><code>ps</code>: class: 'PowerSpectrum'-object
The corresponding (important!) power spectra to be used.</p>
<p><code>lc</code>: class 'Lightcurve'-object
The light curve, whose rms is to be found.</p>
<p><code>m</code>: int
Number of bins per segment.</p>
<p><code>freq_low/freq_high</code>: floats
Lower and upper frequency limits.</p>
<p><code>units</code>: {'abs','frac'}, optional, default: 'abs'
What unit to return the rms in.</p>
<p><strong>Returns</strong>:</p>
<p><code>sigma</code>: np.float
Absolute/fractional rms.</p>
<p><code>sigma_err</code>: np.float
The error in (absolute/fractional) rms. See Eq. (14) of Uttley (2014): "X-ray reverberation around accreting black holes"</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rms_freqband(ps,lc=None,m=None,freq_low=None,freq_high=None,units=&#39;abs&#39;):
    &#34;&#34;&#34;
    Compute the rms in a given frequency band for a given energy (as given by 
    the lightcurve and corresponding power spectrum).
    
    **Parameters**:
    
    `ps`: class: &#39;PowerSpectrum&#39;-object
        The corresponding (important!) power spectra to be used.
        
    `lc`: class &#39;Lightcurve&#39;-object
        The light curve, whose rms is to be found.
    
    `m`: int
        Number of bins per segment.
        
    `freq_low/freq_high`: floats
        Lower and upper frequency limits.
        
    `units`: {&#39;abs&#39;,&#39;frac&#39;}, optional, default: &#39;abs&#39;
        What unit to return the rms in.
        
    **Returns**:
    
    `sigma`: np.float
        Absolute/fractional rms.
    
    `sigma_err`: np.float
        The error in (absolute/fractional) rms. See Eq. (14) of Uttley (2014): &#34;X-ray reverberation around accreting black holes&#34;
    &#34;&#34;&#34;
    
    # Compute rms via light curve first if no freq-boundaries 
    add_to_string = &#39;\n&#39;
    if freq_low == None and freq_high == None:
        if lc != None:
            rms_lc = Fvar_from_lc(lc,m,percent_limit=80) # --&gt; yield the same value
            add_to_string = &#39;, rms_lc = {:.3f}\n&#39;.format(rms_lc)
        
    # Compute rms via power spectrum
    
    # Frequency range
    freq_low = ps.xf[0] if freq_low == None else freq_low
    freq_high = ps.xf[-1] if freq_high == None else freq_high
    dnu = freq_high-freq_low
    
    # Noise Power is constant in freq!
    P_noise = ps.averagePnoise
    
    # Error variance
    if units == &#39;abs&#39;:
        sigma_noise2 = P_noise*dnu*lc.R**2
    elif units == &#39;rms&#39;:
        sigma_noise2 = P_noise*dnu #now it is rather rms, not sigma...
    else:
        print(&#34;You need to pick &#39;abs&#39; or &#39;rms&#39; as unit.&#34;)
    
    # Find rms within the given interval
    xf, [fft_rate,fft_rate_err] = remove_freq(ps.xf,[ps.fft_rate,ps.fft_rate_err],limit=freq_low,geq=True,disregard=True)
    xf, [fft_rate,fft_rate_err] = remove_freq(xf,[fft_rate,fft_rate_err],limit=freq_high,leq=True,disregard=True)
    
    try: 
        rms = np.sqrt(dnu * np.mean(fft_rate)) #\approx same as Fvar_from_ps(xf,fft_rate)
        rms_err = ps.df*np.sqrt(np.sum(fft_rate_err**2))/(2*rms) #error propagation
        
        &#34;&#34;&#34;
        # Version 1: Monte Carlo Estimation 
        # Given one power spectrum (for a given energy) we can use fft_rate (the averages) 
        # and fft_rate_err (the standard errors) to sample new power spectra by sampling new values for the 
        # power spectrum at each frequency point i according to the normal distribution N(fft_rate[i],fft_rate_err[i]).
        num_new_ps = 1000
        # Each frequency bin will yield a num_new_ps-long array that will be appended
        ps_new_v = []
        for i in range(0,len(xf)):
            ps_new_v.append(np.random.normal(fft_rate[i], fft_rate_err[i], num_new_ps))
        # Transpose to make each array become a power spectrum on its own
        ps_new_v = np.transpose(np.array(ps_new_v))
        rms_v = [Fvar_from_ps(xf,f) for f in ps_new_v]
        print(&#39;rms_err_ver1 = &#39;,np.std(rms_v))
        rms_err = np.std(rms_v)

        # Version 2: 
        sigma_err_ver1 = np.sqrt((np.sqrt(1/(2*lc.N))*np.mean(lc.err**2)/(lc.R**2*rms))**2+\
                            (np.sqrt(np.mean(lc.err**2)/lc.N)*1/lc.R)**2) # Eq. B2 Vaughan2003 &#34;On characterizing...&#34; 

        print(&#39;rms_err_ver2 = &#39;,sigma_err_ver1)
        
        # Version 3:
        # In case of unity coherence, the following formula should also work:
        sigma = rms
        sigma_err_ver2 = np.sqrt((2*sigma**2*sigma_noise2+sigma_noise2**2)/(len(lc.t)*sigma**2))
        print(&#39;rms_err_ver3 = &#39;,sigma_err_ver2)
        &#34;&#34;&#34;
 
        if units == &#39;abs&#39;: 
            rms = lc.R*rms
            rms_err = lc.R*rms_err
            &#34;&#34;&#34;
            sigma_err_ver1 = np.sqrt((np.sqrt(1/(2*lc.N))*np.mean(lc.err**2)/(lc.R**2*rms))**2+\
                                     (np.sqrt(np.mean(lc.err**2)/lc.N)*1/lc.R)**2)    
            sigma_err_ver2 = np.sqrt((2*sigma**2*sigma_noise2+sigma_noise2**2)/(len(lc.t)*sigma**2))
            
            rms = sigma
            rms_err = sigma_err
            &#34;&#34;&#34;
            print(&#39;Eband = {:.2f}-{:.2f} keV, Freq range = {:.3f}-{:.3f} Hz, rms_ps = {:.3f} pm {:.3f} ({:.1f}% error), R = {:.3f}&#39;.format(lc.Emin,lc.Emax,freq_low,freq_high,rms,rms_err,rms_err/rms*100,lc.R)+add_to_string)
        else:
            print(&#39;Eband = {:.2f}-{:.2f} keV, Freq range = {:.3f}-{:.3f} Hz, rms_ps = {:.3f} pm {:.3f} ({:.1f}% error)&#39;.format(lc.Emin,lc.Emax,freq_low,freq_high,rms,rms_err,rms_err/rms*100)+add_to_string)
    
    except FloatingPointError:
        rms, rms_err = float(&#39;NaN&#39;), float(&#39;NaN&#39;)
    
    return rms, rms_err</code></pre>
</details>
</dd>
<dt id="stasp.RmsCovariance.rms_vs_energy"><code class="name flex">
<span>def <span class="ident">rms_vs_energy</span></span>(<span>lcs, ps_v, m=None, freq_low=None, freq_high=None, units='rms')</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the fractional variance amplitude (rms) for multiple light curves in a given frequency band.</p>
<p><strong>Parameters</strong>:</p>
<p><code>lcs</code>: class: list of 'Lightcurve'-objects
The light curves to be used.</p>
<p><code>ps_v</code>: class: list of 'PowerSpectrum'-objects
The corresponding (important!) power spectras to be used.</p>
<p><code>m</code>: int
Number of bins per segment.</p>
<p><code>freq_low/freq_high</code>: floats
Lower and upper frequency limits.</p>
<p><code>units</code>: {'abs','frac'}, optional, default: 'abs'
What unit to return the rms in.
</p>
<p><strong>Returns</strong>:</p>
<p><code>energy_mid_v</code>: np.ndarray
The average energy from each light curve's energy band. </p>
<p><code>energy_err_v</code>: np.ndarray
Half the size of each light curve's energy band. </p>
<p><code>rms_v</code>: np.ndarray
Absolute/fractional rms.</p>
<p><code>rms_err_v</code>: np.ndarray
The error in (absolute/fractional) rms.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rms_vs_energy(lcs,ps_v,m=None,freq_low=None,freq_high=None,units=&#39;rms&#39;):
    &#34;&#34;&#34;
    Compute the fractional variance amplitude (rms) for multiple light curves in a given frequency band.
    
    **Parameters**:

    `lcs`: class: list of &#39;Lightcurve&#39;-objects
        The light curves to be used.
    
    `ps_v`: class: list of &#39;PowerSpectrum&#39;-objects
        The corresponding (important!) power spectras to be used.
    
    `m`: int
        Number of bins per segment.
        
    `freq_low/freq_high`: floats
        Lower and upper frequency limits.
        
    `units`: {&#39;abs&#39;,&#39;frac&#39;}, optional, default: &#39;abs&#39;
        What unit to return the rms in.        

           
    **Returns**:

    `energy_mid_v`: np.ndarray 
        The average energy from each light curve&#39;s energy band. 
    
    `energy_err_v`: np.ndarray 
        Half the size of each light curve&#39;s energy band. 
        
    `rms_v`: np.ndarray 
        Absolute/fractional rms.
        
    `rms_err_v`: np.ndarray 
        The error in (absolute/fractional) rms.
    &#34;&#34;&#34;
    
    print(&#39;---------------------------------------------------------------------------------------------------&#39;)
    print(&#39;                           Computing the rms...&#39;)
    print(&#39;---------------------------------------------------------------------------------------------------\n&#39;)
    start = timeit.default_timer()
    
    rms_v, rms_err_v = [], []
    
    for lc,ps in zip(lcs,ps_v):     
        # Find rms                
        rms, rms_err = rms_freqband(ps,lc,m,freq_low,freq_high,units=units)
        
        rms_v.append(rms)
        rms_err_v.append(rms_err)
        
    time_taken = timeit.default_timer()-start
    print(&#39;---------------------------------------------------------------------------------------------------&#39;)
    print(&#39;                           Rms found (in {:.2f} sec).&#39;.format(time_taken))
    print(&#39;---------------------------------------------------------------------------------------------------&#39;)
     
    return np.array(rms_v),np.array(rms_err_v)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="stasp" href="index.html">stasp</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="stasp.RmsCovariance.covariance" href="#stasp.RmsCovariance.covariance">covariance</a></code></li>
<li><code><a title="stasp.RmsCovariance.multiply_w_spectra" href="#stasp.RmsCovariance.multiply_w_spectra">multiply_w_spectra</a></code></li>
<li><code><a title="stasp.RmsCovariance.rms_freqband" href="#stasp.RmsCovariance.rms_freqband">rms_freqband</a></code></li>
<li><code><a title="stasp.RmsCovariance.rms_vs_energy" href="#stasp.RmsCovariance.rms_vs_energy">rms_vs_energy</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>